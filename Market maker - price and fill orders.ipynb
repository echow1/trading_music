{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market marker - price and fill orders\n",
    "\n",
    "Inspo:\n",
    "- https://github.com/cornwarecjp/marketmaker/blob/master/marketmaker.py\n",
    "- https://money.stackexchange.com/questions/24442/how-are-futures-contracts-setup-at-an-exchange\n",
    "- https://pdfs.semanticscholar.org/e0f7/35e27f5f89ecc6dd7d7cad8f6410aff6270f.pdf\n",
    "- https://www.researchgate.net/profile/Bastien-Baldacci/publication/334760288_Algorithmic_market_making_the_case_of_equity_derivatives/links/5e1cf0974585159aa4ce78b8/Algorithmic-market-making-the-case-of-equity-derivatives.pdf\n",
    "\n",
    "3 possibilities for liquidity:\n",
    "1. Treat the underlying asset (the music time series) as the actual asset value $S_t$, which is not tradeable - like weather data. Issue contracts on this underlying non-tradeable asset and build the market around that.\n",
    "2. Issue shares in predictions for the underlying asset according to a stochastic process, auction off to agents, and also play the role of market-maker\n",
    "    - At some point, could jointly optimize the stochastic process, the auction structure and market-making mechanism (simplest: Hanson's LMSR).\n",
    "    - Prep for blockchain style model.\n",
    "3. Fully predictive approach: LMSR where you buy shares for predicting outcome A vs. outcome B. At the end of the outcome, financial reward/loss.\n",
    "    - Number of outstanding shares (corresponding to discrete predicted outcomes) starts at 0 and only grows.\n",
    "        - https://mason.gmu.edu/~rhanson/mktscore.pdf\n",
    "        - http://blog.oddhead.com/2006/10/30/implementing-hansons-market-maker/ - for selling too\n",
    "    - Could build derivatives on top of this later, e.g. make shares tradeable + right to buy/sell share later for given price.\n",
    "    \n",
    "Focus on #3 for now - the most feasible.\n",
    "1. Start with simplest decision problem: predict UP vs. DOWN (buying N shares of up vs. down) for K periods from now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from more_itertools import peekable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import pickle\n",
    "import magenta\n",
    "import os, time, re\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "### change width of notebook display\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# from IPython.core.magic import register_cell_magic\n",
    "# @register_cell_magic('handle')\n",
    "# def handle(line, cell):\n",
    "#     try:\n",
    "#         exec(cell)\n",
    "#     except Exception as e:\n",
    "#         raise # if you want the full trace-back in the notebook\n",
    "\n",
    "JUPYTER_PICKLE_FILE = \"config/shared_jupyter_data.pkl\"\n",
    "def write_shared_jupyter(key, value, path=JUPYTER_PICKLE_FILE, overwrite=False):\n",
    "    if (os.path.exists(path)):\n",
    "        with open(path, \"rb\") as fp:\n",
    "            shared_jupyter_data = pickle.load(fp)\n",
    "        if overwrite:\n",
    "            shared_jupyter_data = {key: value}\n",
    "        else:\n",
    "            shared_jupyter_data[key] = value\n",
    "    else:\n",
    "        shared_jupyter_data = {key: value}\n",
    "    with open(path, 'wb') as fp: \n",
    "        pickle.dump(shared_jupyter_data, fp)\n",
    "\n",
    "def read_shared_jupyter(key=None, path=JUPYTER_PICKLE_FILE):\n",
    "    if (os.path.exists(path)):\n",
    "        with open(path, \"rb\") as fp:\n",
    "            shared_jupyter_data = pickle.load(fp)\n",
    "            if key is not None:\n",
    "                if key in shared_jupyter_data:\n",
    "                    return(shared_jupyter_data[key])\n",
    "                else:\n",
    "                    print(\"Not found!\")\n",
    "                    return(None)\n",
    "            else:\n",
    "                return(shared_jupyter_data)\n",
    "    else:\n",
    "        print(\"No data\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "FIG_WIDTH = 1200\n",
    "FIG_HEIGHT = 800\n",
    "\n",
    "PITCH_MIN = 20\n",
    "PITCH_MAX = 120\n",
    "VELOCITY_MIN = 0\n",
    "VELOCITY_MAX = 120\n",
    "\n",
    "def hheader(x):\n",
    "    print(\"#########################################\")\n",
    "    print(\"### {}\".format(x))\n",
    "    print(\"#########################################\")\n",
    "\n",
    "# Magenta dependencies:\n",
    "# https://github.com/magenta/magenta\n",
    "\n",
    "# Magenta uses pretty_midi to deal with midi files\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate orders for market-making\n",
    "\n",
    "Orders will be to buy or sell shares of A, B, C ... which are the predicted discrete outcomes.\n",
    "\n",
    "Start simple by betting whether will go up or down for (horizon) periods from now.\n",
    "\n",
    "Specifically, a bet is a tuple (quantity, horizon, outcome).\n",
    "\n",
    "https://lobsterdata.com/info/DataStructure.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'order_book_streaming_ts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'order_book_streaming_ts'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-0867c04ecee1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0morder_book_msgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder_book_msgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'event_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bet_outcome'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'direction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# +1 = up, -1 = down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bet_horizon'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'order_book_streaming_ts'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_book_msgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m### generate random order times (monotonically increasing) - something plausible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'order_book_streaming_ts'"
     ]
    }
   ],
   "source": [
    "\n",
    "### order book template data\n",
    "order_book_msgs = pd.read_csv(\"order_book/AMZN_2012-06-21_34200000_57600000_message_1.csv\", header=None)\n",
    "order_book_msgs.columns = ['ts_secs_after_midnight', \"event_type\", \"order_id\", \"bet_quantity\", \"price\", \"direction\"]\n",
    "order_book_msgs['price'] = order_book_msgs['price'] / 1000.0 # in dollars\n",
    "\n",
    "### only look at submitted orders for now\n",
    "order_book_msgs = order_book_msgs.loc[order_book_msgs['event_type'] == 1,].reset_index(drop=True)\n",
    "order_book_msgs['bet_outcome'] = order_book_msgs['direction'] # +1 = up, -1 = down\n",
    "\n",
    "### generate random order times (monotonically increasing) - something plausible\n",
    "# order_book_msgs = order_book_msgs.reset_index()\n",
    "# order_book_msgs['order_book_streaming_ts'] = order_book_msgs['index']\n",
    "order_book_msgs['order_book_streaming_ts'] = np.sort(np.random.gamma(1, np.sqrt(order_book_msgs.shape[0]), order_book_msgs.shape[0]))\n",
    "# start at time 1000 so can weave together streaming order book data and also streaming music data\n",
    "order_book_msgs['order_book_streaming_ts'] = order_book_msgs['order_book_streaming_ts'] + 1000\n",
    "\n",
    "### simulate bet horizon\n",
    "order_book_msgs['bet_horizon'] = order_book_msgs['order_book_streaming_ts'] + np.random.randint(20, 30, order_book_msgs.shape[0])\n",
    "\n",
    "order_book_msgs = order_book_msgs.drop(columns=['ts_secs_after_midnight', 'direction', \"price\"])\n",
    "\n",
    "# price here is set by the market-maker entirely (agents are price-takers)\n",
    "# maybe later can incorporate price-power on the part of the agents\n",
    "\n",
    "### simulate some agent IDs\n",
    "### (assume agents have enough wealth)\n",
    "SIM_N_AGENTS = 100\n",
    "order_book_msgs['agent_id'] = np.random.randint(0, SIM_N_AGENTS, order_book_msgs.shape[0])\n",
    "order_book_msgs = order_book_msgs[['order_book_streaming_ts', 'agent_id', 'order_id', 'bet_outcome', 'bet_horizon', 'bet_quantity']]\n",
    "\n",
    "order_book_msgs.to_csv(\"order_book/simulated_order_book.csv\")\n",
    "\n",
    "order_book_evolv = pd.read_csv(\"order_book/AMZN_2012-06-21_34200000_57600000_message_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_streaming_ts</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>bet_outcome</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009704</td>\n",
       "      <td>96</td>\n",
       "      <td>11885113</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016476</td>\n",
       "      <td>72</td>\n",
       "      <td>16207239</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020087</td>\n",
       "      <td>42</td>\n",
       "      <td>16208720</td>\n",
       "      <td>-1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027996</td>\n",
       "      <td>49</td>\n",
       "      <td>16240373</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032167</td>\n",
       "      <td>57</td>\n",
       "      <td>16240856</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_book_streaming_ts  agent_id  order_id  bet_outcome  quantity\n",
       "0                 0.009704        96  11885113            1        21\n",
       "1                 0.016476        72  16207239           -1       100\n",
       "2                 0.020087        42  16208720           -1        50\n",
       "3                 0.027996        49  16240373           -1       100\n",
       "4                 0.032167        57  16240856           -1       100"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_book_msgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated market-making: read, price and fill orders\n",
    "\n",
    "Remember, in this simple model, we just issue new shares.\n",
    "\n",
    "For the real line:\n",
    "http://yiling.seas.harvard.edu/wp-content/uploads/gao-wine09-interval.pdf\n",
    "\n",
    "Could use Monte Carlo to approximate those integrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set up order book stream \"\"\"\n",
    "\n",
    "### for reading in chunks\n",
    "from collections import deque\n",
    "\n",
    "def csvStream(csvfile):\n",
    "    csv_stream = pd.read_csv(csvfile, index_col=0, iterator=True)\n",
    "    return(csv_stream)\n",
    "\n",
    "### Always fill 1 order at a time\n",
    "def nextChunk(csvStream, chunksize=1):\n",
    "    return(csvStream.get_chunk(chunksize))\n",
    "\n",
    "### Create order book stream\n",
    "orderBookStream = csvStream(\"order_book/simulated_order_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Automated market-making: set up parameters for market-maker\n",
    "\"\"\"\n",
    "\n",
    "MARKET_MAKER_WEALTH = 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-107-34c9deb01616>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-107-34c9deb01616>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    def price_and_update_order(q)\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Automated market-making: LMSR\n",
    "\"\"\"\n",
    "\n",
    "### LMSR parameters\n",
    "b = 1000\n",
    "quantity_shares_up = 0\n",
    "quantity_shares_down = 0\n",
    "def execute_order(quantity, bet_outcome=\"up\"):\n",
    "    if bet_outcome == \"up\":\n",
    "        cost_before = \n",
    "\n",
    "def quote_curr_price():\n",
    "    return()\n",
    "\n",
    "\n",
    "print(\"Upper bound on market-maker loss: {}\".format(b * np.log(2)))\n",
    "\n",
    "\n",
    "iterations = 0\n",
    "while True:\n",
    "    ### Read in current order\n",
    "    currOrder = nextChunk(orderBookStream)\n",
    "    if currOrder is None:\n",
    "        print(\">> End of stream!\")\n",
    "        break\n",
    "    \n",
    "    if (iterations % 1000 == 0):\n",
    "        print(\"Iterations {} ...\".format(iterations+1))\n",
    "\n",
    "    \"\"\" Analysis with current order here \"\"\"\n",
    "\n",
    "    ### Calculate price\n",
    "    \n",
    "    ### Write out price predictio to shared jupyter space\n",
    "        \n",
    "    ### store via Jupyter so other notebooks can access\n",
    "    ### (later work might actually build an API)\n",
    "    raise Exception()\n",
    "    write_shared_jupyter(\"currOrder\", currOrder, overwrite=False)\n",
    "    \n",
    "    ### read trading decisions from other agents\n",
    "\n",
    "    ### Take a short break between analyses (so plotly can catch up)\n",
    "    ### should be >> plot auto-update interval so that all plots\n",
    "    ### update basically at the same time. \n",
    "    time.sleep(1) # 1 second is comfortable for nice UI\n",
    "    iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_streaming_ts</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>direction</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>3.782578</td>\n",
       "      <td>89</td>\n",
       "      <td>27870490</td>\n",
       "      <td>sell</td>\n",
       "      <td>100</td>\n",
       "      <td>2238.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_book_streaming_ts  agent_id  order_id direction  size   price\n",
       "605                 3.782578        89  27870490      sell   100  2238.7"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
