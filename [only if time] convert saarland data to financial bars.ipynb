{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MAESTRO data to financial time bars\n",
    "\n",
    "MAESTRO is Google Magenta's dataset of 200+ hours of annotated piano performance MIDI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import magenta\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "PLOT_WIDTH = 1200\n",
    "PLOT_HEIGHT = 800\n",
    "\n",
    "def hheader(x):\n",
    "    print(\"#########################################\")\n",
    "    print(\"### {}\".format(x))\n",
    "    print(\"#########################################\")\n",
    "\n",
    "# Magenta dependencies:\n",
    "# https://github.com/magenta/magenta\n",
    "\n",
    "# Magenta uses pretty_midi to deal with midi files\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"data/saarland/\"\n",
    "add_input_path = lambda x: \"{}/{}\".format(INPUT_PATH, x).replace(\"//\", \"/\")\n",
    "OUTPUT_PATH = \"data_processed/saarland/\"\n",
    "add_output_path = lambda x: \"{}/{}\".format(OUTPUT_PATH, x).replace(\"//\", \"/\")\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in MIDI metadata and pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in MIDI metadata\n",
    "midi_metadata = pd.read_csv(add_input_path(\"maestro-v3.0.0.csv\"))\n",
    "midi_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "midi_files = []\n",
    "for root, dirs, files in os.walk(INPUT_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".midi\"):\n",
    "            print(os.path.join(root, file))\n",
    "            midi_files.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process pieces by converting into time bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process pieces\n",
    "\"\"\"\n",
    "\n",
    "all_dfs = []\n",
    "for t in range(len(midi_files)):\n",
    "    curr_file = midi_files[t]\n",
    "    print(\"Processing file {} / {} ...\".format(t+1, len(midi_files)))\n",
    "    \n",
    "    midi_test = pretty_midi.PrettyMIDI(curr_file)\n",
    "    solo_piano_part = midi_test.instruments[0]\n",
    "    df_notes = pd.DataFrame([(n.start, n.end, n.pitch, n.velocity, n.duration) for n in solo_piano_part.notes],\n",
    "                            columns=['start', 'end', 'pitch', 'velocity', 'duration'])\n",
    "    ### get metadata\n",
    "    df_metadata = midi_metadata[midi_metadata['midi_filename']==curr_file.replace(INPUT_PATH, \"\").replace(\"\\\\\", \"/\")]\n",
    "    df_metadata = df_metadata.rename(columns={\"duration\": \"total_duration\"})\n",
    "    df_metadata.drop(columns=\"audio_filename\", inplace=True) # don't need audio for now\n",
    "    curr_filename = df_metadata['midi_filename'].values[0].replace(\"/\", \"__\")\n",
    "    \n",
    "    ### combine (so have metadata features for each row)\n",
    "    df_curr = pd.merge(df_notes, df_metadata, how=\"cross\")\n",
    "    \n",
    "    ### need to make sure sorted in order of notes (start)\n",
    "    df_curr = df_curr.sort_values(by='start')\n",
    "    \n",
    "    \"\"\" Process each piece \"\"\"\n",
    "    \n",
    "    ### Make sure everything starts at t=0\n",
    "    ### TODO(echow): will have to update the audio files to also mention this\n",
    "    start_time = float(df_curr['start'].head(1))\n",
    "    df_curr['start_offset_before_first_note'] = start_time\n",
    "    df_curr['start'] = df_curr['start'].apply(lambda x: x - start_time)\n",
    "    df_curr['end'] = df_curr['end'].apply(lambda x: x - start_time)\n",
    "    df_curr['total_duration'] = df_curr['total_duration'].apply(lambda x: x - start_time)\n",
    "    \n",
    "    \"\"\" We have to do some sampling here, because otherwise it is difficult to construct good features.\n",
    "        So, the sampling here will coincide with the music being played in real-time.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" Version 1: time bars\n",
    "        (easiest to play back in real-time)\n",
    "    \"\"\"\n",
    "    EVERY_N_SEC = 1\n",
    "    df_curr_time = df_curr.copy()\n",
    "    df_curr_time['start_sec'] =  (df_curr_time['start'] / EVERY_N_SEC).apply(np.floor).astype(int) * EVERY_N_SEC\n",
    "    # round to N digits\n",
    "    tmp = df_curr_time.select_dtypes(include=[np.number])\n",
    "    df_curr_time.loc[:, tmp.columns] = np.round(tmp, decimals=5)\n",
    "    # add filename\n",
    "    df_curr_time['curr_filename'] = curr_filename\n",
    "    \n",
    "    ### aggregate by sample\n",
    "    ### this is different from the more advanced features we will create - this is only for working\n",
    "    ### with the raw music data at a usable (sampled) level\n",
    "    def str_concat(x): return(','.join([str(s) for s in x]))\n",
    "    df_curr_time_agg = df_curr_time.groupby(['start_sec'], as_index=False).agg({\n",
    "        'start': [np.min, np.mean, np.median, np.max, str_concat],\n",
    "        'end': [np.min, np.mean, np.median, np.max, str_concat],\n",
    "        'pitch': [np.min, np.mean, np.median, np.max, str_concat],\n",
    "        'velocity': [np.min, np.mean, np.median, np.max, str_concat],\n",
    "        'duration': [np.min, np.mean, np.median, np.max, str_concat],\n",
    "        # metadata features - same for all observations\n",
    "        'canonical_composer': [pd.Series.mode],\n",
    "        'split': [pd.Series.mode],\n",
    "        'year': [pd.Series.mode],\n",
    "        'total_duration': [pd.Series.mode],\n",
    "        'curr_filename': [pd.Series.mode] })\n",
    "    df_curr_time_agg.columns = ['_'.join([cc for cc in c if len(cc) > 0]).replace(\"amin\", \"min\").replace(\"amax\", \"max\")\n",
    "                     for c in list(df_curr_time_agg.columns)]\n",
    "    \n",
    "    ### add missing time bars (just for consistency time series analysis - doesn't affect quality of data)\n",
    "    df_curr_time_agg = pd.merge(df_curr_time_agg,\n",
    "                             pd.DataFrame(range(0, df_curr_time_agg.shape[0], 1), columns=[\"start_sec\"]), on=\"start_sec\",\n",
    "                            how='right').sort_values(by=\"start_sec\")\n",
    "    \n",
    "    ### save\n",
    "    curr_fp = curr_filename.replace(\".midi\", \".csv\")\n",
    "    df_curr_time_agg.to_csv(add_output_path(curr_fp))\n",
    "    all_dfs.append(df_curr_time_agg)\n",
    "    \n",
    "    \"\"\" Version 2: information bars\n",
    "        Skip this and volume bars for now - hard to play back in real-time.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\" Version 3: volume bars\n",
    "        Skip this and volume bars for now - hard to play back in real-time.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"... converted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Also create a big music stream from all those MIDI files concatenated,\n",
    "    representing one continuous stream of music\n",
    "\"\"\"\n",
    "\n",
    "df_all_time_agg = pd.concat([df.assign(piece=\"piece_{}\".format(dx)) for dx, df in enumerate(all_dfs)])\n",
    "columns = df_all_time_agg.columns.tolist()[-1:] + df_all_time_agg.columns.tolist()[:-1]\n",
    "df_all_time_agg = df_all_time_agg[columns]\n",
    "\n",
    "### add cumulative start time as well for continuous streaming\n",
    "### this is so we don't get weird time stop and restarts between piece boundaries\n",
    "\n",
    "### preview\n",
    "display(df_all_time_agg.head())\n",
    "print(df_all_time_agg.shape)\n",
    "\n",
    "### save\n",
    "all_fp = \"maestro_full_music_stream.csv\"\n",
    "df_all_time_agg.to_csv(add_output_path(all_fp))\n",
    "print(\"Wrote to: {}\".format(add_output_path(all_fp)))\n",
    "\n",
    "# df_all_time_agg.groupby(['piece']).size().sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
