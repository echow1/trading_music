{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market infrastructure - run music stream and visualize\n",
    "\n",
    "This notebook acts like the raw market data stream for the underlying (music data stream), and also visualizes it in \"real-time\". It also makes the real-time data (bars) available to other applications via Jupyter data storage.\n",
    "\n",
    "- https://medium.com/plotly/introducing-jupyterdash-811f1f57c02e\n",
    "- https://dash.plotly.com/live-updates\n",
    "- https://pbpython.com/interactive-dashboards.html#id6\n",
    "- https://mybinder.org/ + https://github.com/echow1/trading_music\n",
    "- (maybe) https://www.freecodecamp.org/news/how-to-create-auto-updating-data-visualizations-in-python-with-matplotlib-and-aws/\n",
    "- https://kapernikov.com/ipywidgets-with-matplotlib/\n",
    "- https://medium.com/@akoios/titan-tutorial-1-hello-world-c4595bd58c08\n",
    "- https://community.plotly.com/t/how-to-add-restful-api-endpoints-to-a-dash-app/27162/5\n",
    "- https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/quantstrat/sandbox/backtest_musings/research_replication.pdf?root=blotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\echow\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from more_itertools import peekable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import pickle\n",
    "import magenta\n",
    "import os, time, re, json\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "### change width of notebook display\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# for exposing API\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from flask import Flask\n",
    "from flask_restful import Resource, Api\n",
    "\n",
    "JUPYTER_PICKLE_FILE = \"config/shared_jupyter_data.pkl\"\n",
    "def write_shared_jupyter(key, value, path=JUPYTER_PICKLE_FILE, overwrite=False):\n",
    "    if (os.path.exists(path)):\n",
    "        with open(path, \"rb\") as fp:\n",
    "            shared_jupyter_data = pickle.load(fp)\n",
    "        if overwrite:\n",
    "            shared_jupyter_data = {key: value}\n",
    "        else:\n",
    "            shared_jupyter_data[key] = value\n",
    "    else:\n",
    "        shared_jupyter_data = {key: value}\n",
    "    with open(path, 'wb') as fp: \n",
    "        pickle.dump(shared_jupyter_data, fp)\n",
    "\n",
    "def read_shared_jupyter(key=None, path=JUPYTER_PICKLE_FILE):\n",
    "    if (os.path.exists(path)):\n",
    "        with open(path, \"rb\") as fp:\n",
    "            shared_jupyter_data = pickle.load(fp)\n",
    "            if key is not None:\n",
    "                if key in shared_jupyter_data:\n",
    "                    return(shared_jupyter_data[key])\n",
    "                else:\n",
    "                    print(\"Not found!\")\n",
    "                    return(None)\n",
    "            else:\n",
    "                return(shared_jupyter_data)\n",
    "    else:\n",
    "        print(\"No data\")\n",
    "\n",
    "def pandasToJson(df):\n",
    "    return(df.to_json(orient=\"split\"))\n",
    "def jsonToPandas(json):\n",
    "    return(pd.read_json(json, orient=\"split\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "FIG_WIDTH = 1200\n",
    "FIG_HEIGHT = 800\n",
    "\n",
    "PITCH_MIN = 20\n",
    "PITCH_MAX = 120\n",
    "VELOCITY_MIN = 0\n",
    "VELOCITY_MAX = 120\n",
    "\n",
    "def hheader(x):\n",
    "    print(\"#########################################\")\n",
    "    print(\"### {}\".format(x))\n",
    "    print(\"#########################################\")\n",
    "\n",
    "# Magenta dependencies:\n",
    "# https://github.com/magenta/magenta\n",
    "\n",
    "# Magenta uses pretty_midi to deal with midi files\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: read in the music stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set up music stream \"\"\"\n",
    "\n",
    "### for reading in chunks\n",
    "from collections import deque\n",
    "\n",
    "def csvStream(csvfile):\n",
    "    csv_stream = pd.read_csv(csvfile, index_col=0, iterator=True)\n",
    "    return(csv_stream)\n",
    "\n",
    "def nextChunk(csvStream, chunksize=5):\n",
    "    return(csvStream.get_chunk(chunksize))\n",
    "\n",
    "barsQueue = []\n",
    "barSize = 5\n",
    "maxBarsQueueSize = 120\n",
    "\n",
    "def nextChunkWithOverlap(musStream, cq=barsQueue, barSize=barSize, maxNumBars=maxBarsQueueSize):\n",
    "    \"\"\"\n",
    "    Iterate over the music stream with rolling window.\n",
    "    For smoother plotting, set chunksize <<< max number of chunks.\n",
    "    \"\"\"\n",
    "    nextBar = (musStream.get_chunk(barSize))\n",
    "    # make space\n",
    "    if len(cq) >= maxNumBars:\n",
    "        cq.pop(0)\n",
    "    cq.append(nextBar)\n",
    "    #should be sorted always because FIFO but maybe should check.\n",
    "    res = (pd.concat(cq))\n",
    "    ### full current chunk as well as the increment bar added\n",
    "    return(res, nextBar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of music streams found:\n",
      "1\n",
      "['data_processed/maestro/maestro_full_music_stream.csv']\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = \"data_processed/maestro/\"\n",
    "add_input_path = lambda x: \"{}/{}\".format(INPUT_PATH, x)\n",
    "MUSIC_STREAM_SUBSTR = \"maestro_full_music_stream\"\n",
    "\n",
    "music_files = []\n",
    "for root, dirs, files in os.walk(INPUT_PATH):\n",
    "    for file in files:\n",
    "        if MUSIC_STREAM_SUBSTR in file:\n",
    "            music_files.append(os.path.join(root, file))\n",
    "\n",
    "### pick first as the music stream\n",
    "music_files = sorted(music_files) # play in order\n",
    "print(\"Number of music streams found:\")\n",
    "print(len(music_files))\n",
    "print(music_files[:10])\n",
    "\n",
    "### should only 1 have file to stream\n",
    "if (len(music_files) > 1):\n",
    "    whichStream = int(input(\"Index (0 ... N-1) of stream to pick:\"))\n",
    "else:\n",
    "    whichStream = 0\n",
    "musicStream = csvStream(music_files[whichStream])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Stream music audio and display as a webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could just play synthesized MIDI along for now (and replace with real audio later)\n",
    "# have to somehow coordinate with plots with latency etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Stream MIDI and display primitive music statistics (pitch, velocity etc.)\n",
    "\n",
    "(do audio later after download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8100/\n",
      "\n",
      "Dash app running on http://127.0.0.1:8100/\n"
     ]
    }
   ],
   "source": [
    "# import jp_proxy_widget\n",
    "# from scipy.io import wavfile\n",
    "\n",
    "RUN_PLOTS = True\n",
    "DASH_PORT = 8100\n",
    "PLOTLY_REFRESH_SEC = 0.5\n",
    "STREAM_SLEEP_SEC = PLOTLY_REFRESH_SEC * 5\n",
    "\n",
    "if RUN_PLOTS:\n",
    "\n",
    "    \"\"\" Demo: auto-updating time series plot, use with voila and watch update \"\"\"\n",
    "\n",
    "    \"\"\" Set up plot.ly / dash plots to be updated automatically in real-time\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Start Jupyter-Dash app but also expose endpoint for data\n",
    "    ### curl \"http://localhost:<DASH_PORT>/<RESOURCE_ENDPOINT>\"\n",
    "    server = Flask('my_app')\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    # the core Jupyter-Dash app\n",
    "    app = JupyterDash(__name__, server=server, external_stylesheets=external_stylesheets)\n",
    "    api = Api(server)\n",
    "    class HelloWorld(Resource):\n",
    "        \"\"\" Get current snapshot of the music stream.\n",
    "            $ curl \"http://localhost:8100/read\"\n",
    "        \"\"\"\n",
    "        def get(self):\n",
    "            return({\"currTime\": currTime, \"lastBar\": pandasToJson(lastBar)})\n",
    "    api.add_resource(HelloWorld, '/read')\n",
    "    \n",
    "    app.layout = html.Div([\n",
    "        html.H1(\"Music streaming statistics\"),\n",
    "        ### Graph 1: pitch\n",
    "        dcc.Graph(id='pitch_graph'),\n",
    "        ### Graph 2: velocity\n",
    "        dcc.Graph(id='velocity_graph'),\n",
    "        ### Graphs update automatically (separate from the main for-loops for data analysis)\n",
    "        ### Make sure updates faster than the main for-loops (so don't miss any data updates)\n",
    "        ### updates every [interval] milliseconds.\n",
    "        dcc.Interval(id='interval-component', interval=PLOTLY_REFRESH_SEC*1000, n_intervals=0)\n",
    "    # ])\n",
    "    ],     style={'width': '80%', 'float': 'left', 'height': '4.5rem'})\n",
    "\n",
    "    ### Plot #1: pitch info\n",
    "    @app.callback(Output('pitch_graph', 'figure'), Input(\"interval-component\", \"n_intervals\"))\n",
    "    def update_pitch_figure(n=0):\n",
    "        \"\"\"\n",
    "        Update plotly figure. (Like ggplot2: color based on group)\n",
    "        currBar (global): variable with the current data.\n",
    "        \"\"\"\n",
    "        fig = px.line(currChunk, x=\"streaming_start_sec\",\n",
    "                      y=['pitch_median'],\n",
    "                      render_mode=\"webgl\", template=\"plotly_dark\",\n",
    "            title=\"Pitch statistics by sampled bar, streaming\",range_y=[PITCH_MIN, PITCH_MAX]).update_traces(mode='lines')\n",
    "        return(fig)\n",
    "\n",
    "    ### Plot #2: velocity info\n",
    "    @app.callback(Output('velocity_graph', 'figure'), Input(\"interval-component\", \"n_intervals\"))\n",
    "    def update_velocity_figure(n=0):\n",
    "        \"\"\"\n",
    "        Update plotly figure. (Like ggplot2: color based on group)\n",
    "        currBar (global): variable with the current data.\n",
    "        \"\"\"\n",
    "        fig = px.line(currChunk, x=\"streaming_start_sec\",\n",
    "                      y=['velocity_median'],\n",
    "                      render_mode=\"webgl\", template=\"plotly_dark\",\n",
    "            title=\"Velocity statistics by sampled bar, streaming\",range_y=[VELOCITY_MIN, VELOCITY_MAX]).update_traces(mode='lines')\n",
    "        return(fig)\n",
    "\n",
    "    ### Run app locally (inline cuts off output)\n",
    "    app.run_server(mode='external', port=DASH_PORT)\n",
    "\n",
    "iterations = 0\n",
    "currTime = time.time()\n",
    "while True:\n",
    "    currChunk, lastBar = nextChunkWithOverlap(musicStream)\n",
    "    if currChunk is None:\n",
    "        print(\">> End of stream!\")\n",
    "        break\n",
    "    ### Only start when queue is full (seed with initial data)\n",
    "    if len(barsQueue) < maxBarsQueueSize:\n",
    "        iterations += 1\n",
    "        continue\n",
    "    \n",
    "    if (iterations % 1000 == 0):\n",
    "        print(\"Iterations {} ...\".format(iterations+1))\n",
    "        # snapshot data for prototyping (e.g. constructing and simulating music derivatives)\n",
    "        pd.concat(barsQueue).to_csv(\"music_stream_sample.csv\")\n",
    "        \n",
    "    ### store via Jupyter so other notebooks can access\n",
    "    ### (later work might actually build an API)\n",
    "    # causes bugs with Dash + slow\n",
    "    # write_shared_jupyter(\"currChunk\", currChunk, overwrite=True)\n",
    "\n",
    "    \"\"\" Analysis with current bar here \"\"\"\n",
    "\n",
    "    ### read trading decisions from other agents\n",
    "\n",
    "    ### Take a short break between analyses (so plotly can catch up)\n",
    "    ### should be >> plot auto-update interval so that all plots\n",
    "    ### update basically at the same time. \n",
    "    currTime = time.time() # update timestamp before taking break\n",
    "    time.sleep(STREAM_SLEEP_SEC) # 1 second is comfortable for nice UI\n",
    "    iterations += 1\n",
    "    \n",
    "    ### loop back to beginning\n",
    "    if iterations > 600000:\n",
    "        print(\"Looping back to beginning\")\n",
    "        musicStream = csvStream(music_files[whichStream])\n",
    "        chunksQueue = []\n",
    "        iterations = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO later after build rest of market] Task 3: Extract music features from audio in real-time and also make available\n",
    "\n",
    "Sequential learning.\n",
    "- Validate (try out) against the streamed music audio and series.\n",
    "- These are the constructed underlyings for financial derivatives, upon which prediction/regression can work.\n",
    "- Make a local API so other scripts can GET/POST requests (bid/ask) for this.\n",
    "- Will later put Bayesian updates in the for-loop above so can make plot of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEMPO\n",
    "    Strategy: linear Gaussian state space model / Kalman filter.\n",
    "    Model tempo (latent variable zt) as a function of notes etc. (observed variables x1 ... xt)\n",
    "    https://www.researchgate.net/publication/224711190_A_Modified_Kalman_Filtering_Approach_to_On-Line_Musical_Beat_Tracking\n",
    "\"\"\"\n",
    "\n",
    "# test_data = pd.concat(chunksQueue)\n",
    "# print(test_data.shape)\n",
    "# test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HARMONY\n",
    "    (maybe classification from dissonance to consonance? or mood? could of course do actual chords.)\n",
    "\"\"\"\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" RHYTHM\n",
    "\"\"\"\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
